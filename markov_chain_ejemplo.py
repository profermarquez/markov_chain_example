import numpy as np
import matplotlib.pyplot as plt
import arviz as az
import scipy.stats as stats
import emcee

# 游댢 Configuraci칩n de datos
np.random.seed(42)
L = 12  # N칰mero de l칤neas de producci칩n
n = np.random.randint(50, 500, L)  # N칰mero de focos evaluados por l칤nea
true_quality = np.random.normal(80, 10, L)  # Calidad real promedio por l칤nea
y = np.random.normal(true_quality, 5, L)  # Mediciones observadas con ruido
"""
Reducir sigma_y a 2 / np.sqrt(n) hizo que el modelo considerara que 
las mediciones observadas (y) tienen menos incertidumbre, lo que lleva 
a estimaciones que no est치n tan fuertemente atadas a los datos observados. Esto 
permite que la calidad estimada fluct칰e m치s libremente y se diferencie mejor de 
la observada.
"""
sigma_y = 2 / np.sqrt(n)  # Desviaci칩n est치ndar basada en la cantidad de muestras

# 游꿢 Definir el modelo bayesiano
def log_prior(params):
    mu_quality, sigma_quality, *quality = params
    if sigma_quality <= 0:
        return -np.inf  # La desviaci칩n est치ndar debe ser positiva

    lp = stats.norm.logpdf(mu_quality, 80, 15)  # Prior para la calidad global
    lp += stats.halfnorm.logpdf(sigma_quality, scale=15)  # Prior para la variabilidad entre l칤neas
    lp += np.sum(stats.norm.logpdf(quality, mu_quality, sigma_quality))  # Priors para cada l칤nea
    return lp

def log_likelihood(params):
    _, _, *quality = params
    return np.sum(stats.norm.logpdf(y, quality, sigma_y))  # Likelihood

def log_posterior(params):
    lp = log_prior(params)
    if not np.isfinite(lp):
        return -np.inf
    return lp + log_likelihood(params)

# 游댠 Configuraci칩n del MCMC con emcee
ndim = L + 2  # Par치metros: mu_quality, sigma_quality y L valores de calidad
nwalkers = 2*ndim
nsteps = 5000

# Inicializaci칩n de los walkers
initial_pos = np.random.normal(80, 15, (nwalkers, ndim))
initial_pos[:, 1] = np.abs(np.random.normal(15, 5, nwalkers))  # sigma_quality positivo
for i in range(L):
    initial_pos[:, 2 + i] = np.random.normal(80, 10, nwalkers)  # Calidad de cada l칤nea

# 游 Ejecutar el muestreo MCMC
sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior)
sampler.run_mcmc(initial_pos, nsteps, progress=True)

# 游늵 Extraer resultados
samples = sampler.get_chain(discard=1000, thin=10, flat=True)  # Quemar primeros 1000 pasos
posterior_mu_quality = np.median(samples[:, 0])
posterior_sigma_quality = np.median(samples[:, 1])
posterior_quality = np.median(samples[:, 2:], axis=0)

# 游늶 Mostrar resultados
print("\n===== RESULTADOS DEL MODELO BAYESIANO =====")
print(f"N칰mero de l칤neas de producci칩n analizadas: {L}")
print(f"Calidad global promedio estimada: {posterior_mu_quality:.2f}")
print(f"Variabilidad estimada entre l칤neas: {posterior_sigma_quality:.2f}\n")

print("Resultados estimados por l칤nea de producci칩n:")
for i in range(L):
    print(f"  - L칤nea {i+1}: {posterior_quality[i]:.2f} (real: {true_quality[i]:.2f}, observada: {y[i]:.2f})")

# 游늳 Graficar comparaciones entre calidad real, observada y estimada
plt.figure(figsize=(12, 6))
x_labels = [f"L칤nea {i+1}" for i in range(L)]
plt.plot(x_labels, true_quality, 'bo-', label="Calidad Real")
plt.plot(x_labels, y, 'ro-', label="Calidad Observada")
plt.plot(x_labels, posterior_quality, 'go-', label="Calidad Estimada (Bayes)")
plt.xlabel("L칤neas de Producci칩n")
plt.ylabel("Calidad de los Focos")
plt.title("Comparaci칩n entre Calidad Real, Observada y Estimada")
plt.legend()
plt.xticks(rotation=45)
plt.grid()
plt.show()

# 游늵 Mostrar gr치fico de la distribuci칩n de los par치metros globales
az.plot_trace({"mu_quality": samples[:, 0], "sigma_quality": samples[:, 1]})
plt.show()
